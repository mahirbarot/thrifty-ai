{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpXwe0JuxxD7TQm7QNugEt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahirbarot/thrifty-ai/blob/main/task_1_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "def load_txt_documents(folder_path=\"data\"):\n",
        "    \"\"\"\n",
        "    Load all .txt files from the given folder as documents.\n",
        "\n",
        "    \"\"\"\n",
        "    documents = {}\n",
        "    for idx, filename in enumerate(os.listdir(folder_path), start=1):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                text = f.read().strip()\n",
        "            doc_id = f\"doc{idx}\"\n",
        "            documents[doc_id] = {\n",
        "                \"title\": os.path.splitext(filename)[0],\n",
        "                \"text\": text\n",
        "            }\n",
        "    print(f\"Loaded {len(documents)} text documents from '{folder_path}'\")\n",
        "    return documents\n",
        "\n",
        "\n",
        "def embed_documents(docs, model_name='all-MiniLM-L6-v2'):\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Embed all documents using sentence-transformers\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Loading embedding model...\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    doc_ids = []\n",
        "    doc_texts = []\n",
        "    doc_titles = []\n",
        "\n",
        "    for doc_id, doc_data in docs.items():\n",
        "        doc_ids.append(doc_id)\n",
        "        doc_texts.append(doc_data['text'])\n",
        "        doc_titles.append(doc_data['title'])\n",
        "\n",
        "    print(\"Embedding documents...\")\n",
        "    embeddings = model.encode(doc_texts, convert_to_numpy=True)\n",
        "    return model, embeddings, doc_ids, doc_texts, doc_titles\n",
        "\n",
        "\n",
        "def create_faiss_index(embeddings):\n",
        "\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "    # Normalize embeddings before adding to index\n",
        "    normalized_embeddings = embeddings.copy()\n",
        "    faiss.normalize_L2(normalized_embeddings)\n",
        "    index.add(normalized_embeddings)\n",
        "    return index\n",
        "\n",
        "\n",
        "\n",
        "# Retrieve Top K Documents\n",
        "\n",
        "\n",
        "def retrieve_documents(query, model, index, doc_ids, doc_texts, doc_titles, top_k=3):\n",
        "\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "\n",
        "\n",
        "    num_docs = len(doc_ids)\n",
        "    top_k = min(top_k, num_docs)\n",
        "\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    faiss.normalize_L2(query_embedding)\n",
        "    similarities, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    retrieved_docs = []\n",
        "    seen_ids = set()  # Track seen document IDs to avoid duplicates\n",
        "\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        doc_id = doc_ids[idx]\n",
        "\n",
        "        if doc_id in seen_ids:\n",
        "            continue\n",
        "        seen_ids.add(doc_id)\n",
        "\n",
        "        retrieved_docs.append({\n",
        "            'doc_id': doc_id,\n",
        "            'title': doc_titles[idx],\n",
        "            'text': doc_texts[idx],\n",
        "            'similarity_score': float(similarities[0][i])\n",
        "        })\n",
        "\n",
        "    return retrieved_docs\n",
        "\n",
        "\n",
        "def generate_answer(query, retrieved_docs, api_key):\n",
        "\n",
        "    genai.configure(api_key=api_key)\n",
        "    context = \"\\n\\n\".join([\n",
        "        f\"Document: {doc['title']}\\n{doc['text']}\"\n",
        "        for doc in retrieved_docs\n",
        "    ])\n",
        "    prompt = f\"\"\"Based on the following context, answer the question. If the answer cannot be found, say so.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    print(\"\\nGenerating answer using Gemini...\")\n",
        "    model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config=genai.types.GenerationConfig(\n",
        "                temperature=0.3,\n",
        "                max_output_tokens=200,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Check if response has valid content\n",
        "        if response.candidates and response.candidates[0].content.parts:\n",
        "            answer = response.text\n",
        "        else:\n",
        "            answer = \"Could not generate an answer. The response was blocked or empty.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating answer: {e}\")\n",
        "        answer = \"Could not generate an answer due to unavailability of data.\"\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "def calculate_confidence(retrieved_docs):\n",
        "    if not retrieved_docs:\n",
        "        return 0.0\n",
        "\n",
        "    # Filter out invalid similarity scores\n",
        "    valid_scores = [doc['similarity_score'] for doc in retrieved_docs\n",
        "                    if doc['similarity_score'] > -1e10]\n",
        "\n",
        "    if not valid_scores:\n",
        "        return 0.0\n",
        "\n",
        "    avg_similarity = np.mean(valid_scores)\n",
        "\n",
        "    if len(valid_scores) > 1:\n",
        "        gap = valid_scores[0] - valid_scores[1]\n",
        "        confidence = (avg_similarity * 0.7) + (gap * 0.3)\n",
        "    else:\n",
        "        confidence = avg_similarity * 0.7\n",
        "\n",
        "    return float(min(max(confidence, 0), 1))\n",
        "\n",
        "\n",
        "\n",
        "# MAIN\n",
        "\n",
        "def main():\n",
        "    GEMINI_API_KEY = \"AIzaSyCfo3sw-31M5Xu3U8sLvEelFRLvZrzra-8\"\n",
        "\n",
        "    # Load text files as documents\n",
        "    documents = load_txt_documents(\"data\")\n",
        "\n",
        "    model, embeddings, doc_ids, doc_texts, doc_titles = embed_documents(documents)\n",
        "    index = create_faiss_index(embeddings)\n",
        "\n",
        "    queries = [\n",
        "        \"What is redis?\",\n",
        "        \"Which star is in center of solar system?\",  # out of context question\n",
        "        \"What is react?\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        retrieved_docs = retrieve_documents(query, model, index, doc_ids, doc_texts, doc_titles, top_k=3)\n",
        "        answer = generate_answer(query, retrieved_docs, GEMINI_API_KEY)\n",
        "        confidence = calculate_confidence(retrieved_docs)\n",
        "\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(\"RESULTS\")\n",
        "        print(\"-\"*80)\n",
        "        print(f\"\\nFinal Answer:\\n{answer}\")\n",
        "        print(\"\\nRetrieved Documents:\")\n",
        "        for i, doc in enumerate(retrieved_docs, 1):\n",
        "            print(f\"Doc ID:{i}. {doc['title']} (similarity score: {doc['similarity_score']:.4f})\")\n",
        "        print(f\"\\nOverall Confidence Score: {confidence:.4f}\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X7YKa0gMLFAC",
        "outputId": "8147e3ba-18bb-43ec-b022-59597f03e4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 6 text documents from 'data'\n",
            "Loading embedding model...\n",
            "Embedding documents...\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Query: What is redis?\n",
            "\n",
            "Generating answer using Gemini...\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "RESULTS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Final Answer:\n",
            "Redis is an in-memory data structure store used as a cache, message broker, and database.\n",
            "\n",
            "\n",
            "Retrieved Documents:\n",
            "Doc ID:1. redis (similarity score: 0.5846)\n",
            "Doc ID:2. fastapi (similarity score: 0.1877)\n",
            "Doc ID:3. git (similarity score: 0.1649)\n",
            "\n",
            "Overall Confidence Score: 0.3377\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Query: Which star is in center of solar system?\n",
            "\n",
            "Generating answer using Gemini...\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "RESULTS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Final Answer:\n",
            "The provided documents do not contain information about the star at the center of the solar system.\n",
            "\n",
            "\n",
            "Retrieved Documents:\n",
            "Doc ID:1. git (similarity score: 0.1202)\n",
            "Doc ID:2. redis (similarity score: 0.1165)\n",
            "Doc ID:3. fastapi (similarity score: 0.0528)\n",
            "\n",
            "Overall Confidence Score: 0.0687\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Query: What is react?\n",
            "\n",
            "Generating answer using Gemini...\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "RESULTS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Final Answer:\n",
            "React is a JavaScript library for building user interfaces.\n",
            "\n",
            "\n",
            "Retrieved Documents:\n",
            "Doc ID:1. react (similarity score: 0.7029)\n",
            "Doc ID:2. git (similarity score: 0.2127)\n",
            "Doc ID:3. docker (similarity score: 0.1664)\n",
            "\n",
            "Overall Confidence Score: 0.3995\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}